# using-Gradio-Sign-Language-Interpreter-2

This AI project utilizes CNN to recognize hand gestures in real-time. It uses MediaPipe for detecting hand landmarks and a TensorFlow Lite model for gesture classification. The system is built with a Gradio interface, allowing users to upload images, accessing webcam instantly or even paste a sign language picture from clipboard for gesture recognition. The detected hand gestures are processed and classified, with the results displayed on the interface along with the confidence levels of the predictions. This project aims to provide an interactive tool for recognizing and learning hand gestures.

Need to run the "gradio_Lite_model.py" file.
Then a Local URL will be generated which need to be clicked to use the application.
